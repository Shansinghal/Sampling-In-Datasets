{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTNxmrbvIIAv"
      },
      "source": [
        "## Sampling Assignment\n",
        "### **Objective:** Analyze how different sampling techniques affect the performance of various ML models on a balanced credit card dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGtbNEm2IXQH",
        "outputId": "9aec5b8d-e9d6-4be7-bd3b-9a0fa5152b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (0.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries if not already installed\n",
        "!pip install pandas numpy scikit-learn imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n0m7hnepG9PC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpB9ooAaIi1C",
        "outputId": "8721ba13-ae2f-4b9e-9c6f-58d197798c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n",
            "Original Class Distribution:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "# 1. Load the Dataset\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "try:\n",
        "    data = pd.read_csv(url)\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except:\n",
        "    print(\"Failed to load URL. Please download the CSV and load it locally.\")\n",
        "\n",
        "print(\"Original Class Distribution:\")\n",
        "print(data['Class'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FmTP-t5I6U-",
        "outputId": "82699662-18d0-49a6-8b44-554acc2cd9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Balanced Class Distribution:\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# ## 2. Balance the Dataset\n",
        "# Converting the imbalanced dataset into a balanced one using SMOTE (Synthetic Minority Over-sampling Technique).\n",
        "# Separating features and target\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Create a new balanced dataframe\n",
        "balanced_df = pd.concat([pd.DataFrame(X_balanced, columns=X.columns), pd.Series(y_balanced, name='Class')], axis=1)\n",
        "\n",
        "print(\"\\nBalanced Class Distribution:\")\n",
        "print(balanced_df['Class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egoQWyhXJT-b"
      },
      "source": [
        "### 3. Define Sampling Techniques\n",
        "We will create 5 distinct samples using different formulas/methods\n",
        "\n",
        "###**Techniques used:**\n",
        "1. Simple Random Sampling\n",
        "2. Stratified Sampling\n",
        "3. Systematic Sampling\n",
        "4. Cluster Sampling\n",
        "5. Bootstrap Sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB6MesHxJLjG",
        "outputId": "e5a1947a-94a5-4a36-8a48-d18e9a667de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculated Sample Size (Cochran's Formula): 385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-324281032.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby('Class', group_keys=False).apply(lambda x: x.sample(int(n/2), random_state=42))\n"
          ]
        }
      ],
      "source": [
        "# Sample Size Calculation (using Cochran's Formula for representative size as a baseline)\n",
        "# n = (Z^2 * p * (1-p)) / E^2\n",
        "# Assuming 95% confidence level (Z=1.96), p=0.5, E=0.05\n",
        "Z = 1.96\n",
        "p = 0.5\n",
        "E = 0.05\n",
        "sample_size_cochran = math.ceil((Z**2 * p * (1-p)) / E**2)\n",
        "print(f\"Calculated Sample Size (Cochran's Formula): {sample_size_cochran}\")\n",
        "\n",
        "# --- SAMPLING FUNCTIONS ---\n",
        "\n",
        "def simple_random_sampling(df, n):\n",
        "    return df.sample(n=n, random_state=42)\n",
        "\n",
        "def stratified_sampling(df, n):\n",
        "    # Stratified by Class to ensure equal representation in the sample\n",
        "    return df.groupby('Class', group_keys=False).apply(lambda x: x.sample(int(n/2), random_state=42))\n",
        "\n",
        "def systematic_sampling(df, n):\n",
        "    k = len(df) // n\n",
        "    start = np.random.randint(0, k)\n",
        "    return df.iloc[start::k].iloc[:n]\n",
        "\n",
        "def cluster_sampling(df, n_clusters=5):\n",
        "    # Creating pseudo-clusters for demonstration since no natural clusters exist in anonymized data\n",
        "    df_copy = df.copy()\n",
        "    df_copy['cluster'] = np.random.randint(0, n_clusters, size=len(df))\n",
        "    # Select random clusters\n",
        "    selected_clusters = np.random.choice(range(n_clusters), size=2, replace=False)\n",
        "    sample = df_copy[df_copy['cluster'].isin(selected_clusters)]\n",
        "    return sample.drop('cluster', axis=1)\n",
        "\n",
        "def bootstrap_sampling(df, n):\n",
        "    # Sampling with replacement\n",
        "    return df.sample(n=n, replace=True, random_state=42)\n",
        "\n",
        "# Create the 5 samples\n",
        "# We generally use the calculated sample size, but for Cluster we take whole clusters.\n",
        "samples = {\n",
        "    \"Sampling1 (Simple Random)\": simple_random_sampling(balanced_df, sample_size_cochran),\n",
        "    \"Sampling2 (Stratified)\": stratified_sampling(balanced_df, sample_size_cochran),\n",
        "    \"Sampling3 (Systematic)\": systematic_sampling(balanced_df, sample_size_cochran),\n",
        "    \"Sampling4 (Cluster)\": cluster_sampling(balanced_df),\n",
        "    \"Sampling5 (Bootstrap)\": bootstrap_sampling(balanced_df, sample_size_cochran)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W60Lyd1MJshs"
      },
      "outputs": [],
      "source": [
        "# 4. Define Models (M1 to M5)\n",
        "models = {\n",
        "    \"M1 (Logistic Regression)\": LogisticRegression(max_iter=1000),\n",
        "    \"M2 (Decision Tree)\": DecisionTreeClassifier(random_state=42),\n",
        "    \"M3 (Random Forest)\": RandomForestClassifier(random_state=42),\n",
        "    \"M4 (SVM)\": SVC(),\n",
        "    \"M5 (Naive Bayes)\": GaussianNB()\n",
        "}\n",
        "\n",
        "# 5. Train and Evaluate\n",
        "# Applying every model on every sampling technique and recording accuracy[cite: 19, 20].\n",
        "results = {}\n",
        "\n",
        "for sample_name, sample_data in samples.items():\n",
        "    # Split features and target for the current sample\n",
        "    X_sample = sample_data.drop('Class', axis=1)\n",
        "    y_sample = sample_data['Class']\n",
        "\n",
        "    # Split into train and test sets (80-20 split)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale the data (important for Logistic Regression and SVM)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    sample_results = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        # Train model\n",
        "        if \"Logistic\" in model_name or \"SVM\" in model_name:\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            preds = model.predict(X_test_scaled)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            preds = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        sample_results[model_name] = round(acc * 100, 2)\n",
        "    results[sample_name] = sample_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMlbmW8CJ9xA",
        "outputId": "edbad982-0e02-46bd-9c6e-dc235e062980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          Sampling1 (Simple Random)  Sampling2 (Stratified)  \\\n",
            "M1 (Logistic Regression)                      88.31                   90.91   \n",
            "M2 (Decision Tree)                            94.81                   96.10   \n",
            "M3 (Random Forest)                            97.40                   98.70   \n",
            "M4 (SVM)                                      90.91                   98.70   \n",
            "M5 (Naive Bayes)                              88.31                   85.71   \n",
            "\n",
            "                          Sampling3 (Systematic)  Sampling4 (Cluster)  \\\n",
            "M1 (Logistic Regression)                   93.51                95.12   \n",
            "M2 (Decision Tree)                         94.81                94.31   \n",
            "M3 (Random Forest)                         98.70                98.37   \n",
            "M4 (SVM)                                   94.81                96.75   \n",
            "M5 (Naive Bayes)                           77.92                70.73   \n",
            "\n",
            "                          Sampling5 (Bootstrap)  \n",
            "M1 (Logistic Regression)                  96.10  \n",
            "M2 (Decision Tree)                        92.21  \n",
            "M3 (Random Forest)                        97.40  \n",
            "M4 (SVM)                                  96.10  \n",
            "M5 (Naive Bayes)                          85.71  \n"
          ]
        }
      ],
      "source": [
        "# 6. Results and Discussion\n",
        "# Convert results to DataFrame for nice display\n",
        "results_df = pd.DataFrame(results)\n",
        "# Transpose to match the assignment table format (Rows=Models, Cols=Samplings)\n",
        "final_table = results_df\n",
        "print(final_table)\n",
        "# Save to CSV (Optional)\n",
        "final_table.to_csv(\"sampling_results.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
